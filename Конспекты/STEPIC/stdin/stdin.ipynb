{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world!from\n",
      "python\n",
      "Bye-bye\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print('Hello')\n",
    "sys.stdout.write('world!')\n",
    "print('from')\n",
    "sys.stdout.write('python\\n')\n",
    "print('Bye-bye')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Информзащита\n",
      "Форс\n",
      "OFT group\n",
      "Oracle\n",
      "Atos\n",
      "Микрон\n",
      "Гринатом\n",
      "ХайТэк\n",
      "Сател\n",
      "Лига Цифровой Экономики\n",
      "TerraLink\n",
      "АйТеко\n",
      "Itransition\n",
      "Эвотор\n",
      "Angara\n",
      "OCS Distribution\n",
      "Hikvision\n",
      "Тринити\n",
      "iCore\n",
      "Ростелеком\n",
      "Сигма\n",
      "Аквариус\n",
      "Philax\n",
      "Softline\n",
      "IBS\n",
      "Инфосистемы Джет\n",
      "Ситроникс\n",
      "ИнфоТеКС\n",
      "Инлайн Груп\n",
      "Элтекс\n"
     ]
    }
   ],
   "source": [
    "from  csv import *\n",
    "with open(\"salary_data.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    d = reader(f,delimiter=\";\")\n",
    "    next(d)\n",
    "    my_dict={}\n",
    "    for com,slr in d:\n",
    "        my_dict[com] = my_dict.get(com,[]) + [int(slr)]\n",
    "    res = sorted(my_dict.keys(),key=lambda x: (sum(my_dict[x]) / len(my_dict[x]),x))\n",
    "    print(*res,sep=\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  csv import *\n",
    "n = int(input()) - 1\n",
    "with open(\"deniro.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    d = list(reader(f))\n",
    "    d = sorted(d,key= lambda x: x[n])\n",
    "[print(*i,sep=\",\") for i in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def csv_columns(filename):\n",
    "\n",
    "    with open(filename, encoding=\"utf-8\") as file_in:\n",
    "        rows = list(csv.reader(file_in))\n",
    "        return {key: value for key, *value in zip(*rows)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie': ['Machete', \"Marvin's Room\", 'Raging Bull', \"This Boy's Life\", 'Silver Linings Playbook', 'Taxi Driver', 'Jackie Brown', 'Shark Tale', 'Bang the Drum Slowly', 'Analyze That', 'Meet the Parents', 'Wag the Dog', 'The Big Wedding', 'Night and the City', 'Backdraft', 'The Untouchables', 'Cop Land', 'Thunderheart', 'Being Flynn', \"We're No Angels\", 'Limitless', 'The Bag Man', 'The Good Shepherd', 'Jacknife', 'Righteous Kill', 'Mad Dog and Glory', 'Brazil', \"Mary Shelley's Frankenstein\", 'Stone', 'Killer Elite', 'A Bronx Tale', 'Falling in Love', 'The Adventures of Rocky & Bullwinkle', 'Red Lights', 'The Score', \"New Year's Eve\", 'Ronin', 'Midnight Run', 'Last Vegas', 'Born to Win', 'Angel Heart', 'City by the Sea', 'Cape Fear', \"Everybody's Fine\", 'Goodfellas', '15 Minutes', 'Mistress', 'Hide and Seek', 'The Intern', 'Awakenings', 'Joy', 'Mean Streets', 'The Deer Hunter', 'Great Expectations', 'True Confessions', 'The Mission', 'Killing Season', 'The King of Comedy', 'New York', 'Rent', 'Once Upon a Time in America', 'Meet the Fockers', 'Bloody Mama', 'The Last Tycoon', 'Grudge Match', 'Analyze This', 'The Bridge of San Luis Rey', 'Guilty by Suspicion', 'What Just Happened?', 'Heat', 'Godsend', 'Captain Shakespeare', 'Flawless', 'Stanley & Iris', 'Arthur and the Invisibles', 'Greetings', 'Little Fockers', 'Sleepers', 'Dirty Grandpa', 'Dear America: Letters Home From Vietnam', 'Casino', 'The Fan', 'Heist', 'Men of Honor'], 'year': ['2010', '1996', '1980', '1993', '2012', '1976', '1997', '2004', '1973', '2002', '2000', '1997', '2013', '1992', '1991', '1987', '1997', '1992', '2012', '1989', '2011', '2014', '2006', '1989', '2008', '1993', '1985', '1994', '2010', '2011', '1993', '1984', '2000', '2012', '2001', '2011', '1998', '1988', '2013', '1971', '1987', '2002', '1991', '2009', '1990', '2001', '1991', '2005', '2015', '1990', '2015', '1973', '1978', '1998', '1981', '1986', '2013', '1983', '1977', '2005', '1984', '2004', '1970', '1976', '2013', '1999', '2005', '1991', '2008', '1995', '2003', '2007', '1999', '1990', '2007', '1968', '2010', '1996', '2016', '1987', '1995', '1996', '2015', '2000'], 'rating': ['72', '80', '97', '75', '92', '99', '87', '35', '88', '27', '84', '85', '7', '67', '71', '80', '72', '87', '51', '47', '70', '9', '54', '64', '19', '78', '98', '39', '50', '25', '96', '60', '43', '29', '73', '7', '68', '96', '46', '40', '78', '48', '76', '46', '96', '33', '69', '13', '61', '88', '60', '98', '93', '38', '75', '65', '11', '90', '67', '46', '89', '38', '17', '41', '29', '69', '4', '65', '51', '86', '4', '76', '43', '29', '21', '86', '10', '74', '11', '100', '80', '38', '26', '41']}\n",
      "{'name': ['Timur', 'Arthur', 'Anri'], 'grade': ['5', '4', '5']}\n"
     ]
    }
   ],
   "source": [
    "# INPUT DATA:\n",
    "\n",
    "# TEST_1:\n",
    "text = '''movie,year,rating\n",
    "Machete,2010,72\n",
    "Marvin's Room,1996,80\n",
    "Raging Bull,1980,97\n",
    "This Boy's Life,1993,75\n",
    "Silver Linings Playbook,2012,92\n",
    "Taxi Driver,1976,99\n",
    "Jackie Brown,1997,87\n",
    "Shark Tale,2004,35\n",
    "Bang the Drum Slowly,1973,88\n",
    "Analyze That,2002,27\n",
    "Meet the Parents,2000,84\n",
    "Wag the Dog,1997,85\n",
    "The Big Wedding,2013,7\n",
    "Night and the City,1992,67\n",
    "Backdraft,1991,71\n",
    "The Untouchables,1987,80\n",
    "Cop Land,1997,72\n",
    "Thunderheart,1992,87\n",
    "Being Flynn,2012,51\n",
    "We're No Angels,1989,47\n",
    "Limitless,2011,70\n",
    "The Bag Man,2014,9\n",
    "The Good Shepherd,2006,54\n",
    "Jacknife,1989,64\n",
    "Righteous Kill,2008,19\n",
    "Mad Dog and Glory,1993,78\n",
    "Brazil,1985,98\n",
    "Mary Shelley's Frankenstein,1994,39\n",
    "Stone,2010,50\n",
    "Killer Elite,2011,25\n",
    "A Bronx Tale,1993,96\n",
    "Falling in Love,1984,60\n",
    "The Adventures of Rocky & Bullwinkle,2000,43\n",
    "Red Lights,2012,29\n",
    "The Score,2001,73\n",
    "New Year's Eve,2011,7\n",
    "Ronin,1998,68\n",
    "Midnight Run,1988,96\n",
    "Last Vegas,2013,46\n",
    "Born to Win,1971,40\n",
    "Angel Heart,1987,78\n",
    "City by the Sea,2002,48\n",
    "Cape Fear,1991,76\n",
    "Everybody's Fine,2009,46\n",
    "Goodfellas,1990,96\n",
    "15 Minutes,2001,33\n",
    "Mistress,1991,69\n",
    "Hide and Seek,2005,13\n",
    "The Intern,2015,61\n",
    "Awakenings,1990,88\n",
    "Joy,2015,60\n",
    "Mean Streets,1973,98\n",
    "The Deer Hunter,1978,93\n",
    "Great Expectations,1998,38\n",
    "True Confessions,1981,75\n",
    "The Mission,1986,65\n",
    "Killing Season,2013,11\n",
    "The King of Comedy,1983,90\n",
    "New York,1977,67\n",
    "Rent,2005,46\n",
    "Once Upon a Time in America,1984,89\n",
    "Meet the Fockers,2004,38\n",
    "Bloody Mama,1970,17\n",
    "The Last Tycoon,1976,41\n",
    "Grudge Match,2013,29\n",
    "Analyze This,1999,69\n",
    "The Bridge of San Luis Rey,2005,4\n",
    "Guilty by Suspicion,1991,65\n",
    "What Just Happened?,2008,51\n",
    "Heat,1995,86\n",
    "Godsend,2003,4\n",
    "Captain Shakespeare,2007,76\n",
    "Flawless,1999,43\n",
    "Stanley & Iris,1990,29\n",
    "Arthur and the Invisibles,2007,21\n",
    "Greetings,1968,86\n",
    "Little Fockers,2010,10\n",
    "Sleepers,1996,74\n",
    "Dirty Grandpa,2016,11\n",
    "Dear America: Letters Home From Vietnam,1987,100\n",
    "Casino,1995,80\n",
    "The Fan,1996,38\n",
    "Heist,2015,26\n",
    "Men of Honor,2000,41'''\n",
    "\n",
    "with open('deniro.csv', 'w') as file:\n",
    "    file.write(text)\n",
    "\n",
    "print(csv_columns('deniro.csv'))\n",
    "\n",
    "# TEST_2:\n",
    "text = '''name,grade\n",
    "Timur,5\n",
    "Arthur,4\n",
    "Anri,5'''\n",
    "\n",
    "with open('grades.csv', 'w') as file:\n",
    "    file.write(text)\n",
    "\n",
    "print(csv_columns('grades.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import *\n",
    "with open(\"data1.csv\", \"r\", encoding=\"utf-8\") as f, open(\"domain_usage.csv\", \"w\", encoding=\"utf-8\",newline='') as d:\n",
    "    rows = reader(f,delimiter=\"@\")\n",
    "    next(rows)\n",
    "    my_dict={}\n",
    "    for el,k in rows:\n",
    "        my_dict[k] = my_dict.get(k,0) + 1\n",
    "    col = [\"domain\", \"count\"]\n",
    "    w = writer(d)\n",
    "    w.writerow(col)\n",
    "    for k in sorted(my_dict.keys(),key= lambda x: (my_dict[x],x)):\n",
    "        w.writerow([k,my_dict[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master. Gerios Moubarek\n",
      "Master. Alden Gates Caldwell\n",
      "Master. Elias Nicola-Yarred\n",
      "Master. Frank John William Goldsmith\n",
      "Master. Richard F Becker\n",
      "Master. Michel M Navratil\n",
      "Mr. Victor Francis Sunderland\n",
      "Master. Edvin Rojj Felix Asplund\n",
      "Master. Hudson Trevor Allison\n",
      "Master. Edmond Roger Navratil\n",
      "Master. William Loch Coutts\n",
      "Master. William Rowe Richards\n",
      "Master. Washington Dodge\n",
      "Master. Eden Leslie Coutts\n",
      "Master. John Morgan Jr Davies\n",
      "Mr. John Borland Jr Thayer\n",
      "Master. Halim Gonios Moubarek\n",
      "Master. Meier Moor\n",
      "Master. Viljo Hamalainen\n",
      "Master. Bertram Vere Dean\n",
      "Master. William Thornton II Carter\n",
      "Master. Assad Alexander Thomas\n",
      "Master. Andre Mallet\n",
      "Master. George Sibley Richards\n",
      "Master. Harold Theodor Johnson\n",
      "Mrs. Nicholas (Adele Achem) Nasser\n",
      "Miss. Marguerite Rut Sandstrom\n",
      "Miss. Anna McGowan\n",
      "Miss. Jamila Nicola-Yarred\n",
      "Miss. Simonne Marie Anne Andree Laroche\n",
      "Miss. Constance Mirium West\n",
      "Miss. Erna Alexandra Andersson\n",
      "Miss. Bertha Ilett\n",
      "Miss. Anna Peter\n",
      "Miss. Katherine Gilnagh\n",
      "Miss. Eleanor Ileen Johnson\n",
      "Miss. Luise Gretchen Kink-Heilmann\n",
      "Miss. Helen Carr\n",
      "Miss. Lillian Gertrud Asplund\n",
      "Miss. Marjorie Collyer\n",
      "Mrs. Victor de Satode (Maria Josefa Perez de Soto y Vallejo) Penasco y Castellana\n",
      "Miss. Jean Gertrude Hippach\n",
      "Miss. Maria Nakid\n",
      "Miss. Bertha Lehmann\n",
      "Miss. Lucile Polk Carter\n",
      "Miss. Madeleine Violet Mellinger\n",
      "Miss. Marie Catherine Baclini\n",
      "Miss. Helene Barbara Baclini\n",
      "Miss. Hildur E Hirvonen\n",
      "Miss. Roberta Maioni\n",
      "Miss. Phyllis May Quick\n",
      "Miss. Eva Miriam Hart\n",
      "Miss. Marion Louise Becker\n",
      "Miss. Eugenie Baclini\n",
      "Miss. Hanora O'Leary\n",
      "Miss. Georgette Alexandra Madill\n",
      "Miss. Manca Karun\n",
      "Miss. Annie Jessie Harper\n",
      "Miss. Joan Wells\n",
      "Miss. Virginia Ethel Emanuel\n",
      "Miss. Banoura Ayoub\n",
      "Mrs. Albert Adrian (Vera Gillespie) Dick\n",
      "Mrs. Antoni (Selini Alexander) Yasbeck\n",
      "Miss. Mary Conover Lines\n",
      "Miss. Adele Kiamie Najib\n"
     ]
    }
   ],
   "source": [
    "from csv import *\n",
    "with open(\"titanic.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    rows = reader(f,delimiter=\";\")\n",
    "    next(rows)\n",
    "    male = []\n",
    "    female = []\n",
    "    for surv, name, sex, age in rows:\n",
    "        if float(age) < 18 and surv == \"1\":\n",
    "            if sex == \"female\":\n",
    "                female.append(name)\n",
    "            else:\n",
    "                male.append(name)\n",
    "for i in male + female:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def condense_csv(filename, id_name):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        objects = {}\n",
    "        rows = reader(f)\n",
    "        for obj, arts, val in rows:\n",
    "            if obj not in objects:\n",
    "                objects[obj] = {id_name: obj}\n",
    "            objects[obj][arts] = val\n",
    "    with open(\"condensed.csv\", \"w\", encoding=\"utf-8\") as w:\n",
    "        wr = DictWriter(w, fieldnames= objects[obj])\n",
    "        wr.writeheader()\n",
    "        wr.writerows(objects.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,Artist,Title,Time\n",
      "\n",
      "01,Otis Taylor,Ran So Hard the Sun Went Down,3:52\n",
      "\n",
      "02,Waylon Jennings,Honky Tonk Heroes (Like Me),3:29\n"
     ]
    }
   ],
   "source": [
    "# INPUT DATA:\n",
    "\n",
    "# # TEST_1:\n",
    "# text = '''01,Title,Ran So Hard the Sun Went Down\n",
    "# 02,Title,Honky Tonk Heroes (Like Me)'''\n",
    "\n",
    "# with open('data.csv', 'w', encoding='utf-8') as file:\n",
    "#     file.write(text)\n",
    "\n",
    "# condense_csv('data.csv', id_name='ID')\n",
    "\n",
    "# with open('condensed.csv', encoding='utf-8') as file:\n",
    "#     print(file.read().strip())\n",
    "\n",
    " # TEST_2:\n",
    "text = '''01,Artist,Otis Taylor\n",
    "01,Title,Ran So Hard the Sun Went Down\n",
    "01,Time,3:52\n",
    "02,Artist,Waylon Jennings\n",
    "02,Title,Honky Tonk Heroes (Like Me)\n",
    "02,Time,3:29'''\n",
    "\n",
    "with open('data.csv', 'w', encoding='utf-8') as file:\n",
    "    file.write(text)\n",
    "\n",
    "condense_csv('data.csv', id_name='ID')\n",
    "\n",
    "with open('condensed.csv', encoding='utf-8') as file:\n",
    "    print(file.read().strip())\n",
    "\n",
    "# # TEST_3:\n",
    "# text = '''01,Artist,Otis Taylor\n",
    "# 01,Title,Ran So Hard the Sun Went Down\n",
    "# 01,Time,3:52\n",
    "# 02,Artist,Waylon Jennings\n",
    "# 02,Title,Honky Tonk Heroes (Like Me)\n",
    "# 02,Time,3:29\n",
    "# 03,Artist,David Allan Coe\n",
    "# 03,Title,Willie Waylon And Me\n",
    "# 03,Time,3:26'''\n",
    "\n",
    "# with open('data.csv', 'w', encoding='utf-8') as file:\n",
    "#     file.write(text)\n",
    "\n",
    "# condense_csv('data.csv', id_name='Position')\n",
    "\n",
    "# with open('condensed.csv', encoding='utf-8') as file:\n",
    "#     print(file.read().strip())\n",
    "\n",
    "# # TEST_4:\n",
    "# text = '''ball,color,purple\n",
    "# ball,size,4\n",
    "# ball,notes,it's round\n",
    "# cup,color,blue\n",
    "# cup,size,1\n",
    "# cup,notes,none'''\n",
    "\n",
    "# with open('data.csv', 'w', encoding='utf-8') as file:\n",
    "#     file.write(text)\n",
    "\n",
    "# condense_csv('data.csv', id_name='ID')\n",
    "\n",
    "# with open('condensed.csv', encoding='utf-8') as file:\n",
    "#     print(file.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condense_csv('data.csv', id_name='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import *\n",
    "with open(\"student_counts.csv\", \"r\", encoding=\"utf-8\") as f , open(\"sorted_student_counts.csv\", \"w\", encoding=\"utf-8\",newline=\"\") as w:\n",
    "    rows = DictReader(f)\n",
    "    col = sorted(rows.fieldnames,key=lambda x: (int(x.split(\"-\")[0]), x.split(\"-\")[1]) if x.split(\"-\")[0].isdigit() else (0,x))\n",
    "    \n",
    "    wr = DictWriter(w, fieldnames= col)\n",
    "    wr.writeheader()\n",
    "    wr.writerows(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Творог Гречка Рис Бородинский хлеб Яблоки Пельмени Овсяное печенье Спагетти Печеная фасоль Мороженое Фарш Вареники Картофель Батончик\n"
     ]
    }
   ],
   "source": [
    "from csv import *\n",
    "with open(\"prices.csv\", \"r\" , encoding=\"utf-8\") as f:\n",
    "    readers = DictReader(f,delimiter=\";\") \n",
    "    dm = {i:\"\" for i in list(readers.fieldnames)[1:]}\n",
    "    dt = dm.copy()\n",
    "    for i in readers: # перебераем магазины\n",
    "        m, *n = list(i.keys()) \n",
    "        for k in n: # перебкраем товары\n",
    "            if dt[k]:\n",
    "                if int(dt[k]) < int(i[k]):\n",
    "                    dt[k] = i[k]\n",
    "                    dm[k] = i[m]\n",
    "                elif int(dt[k]) == int(i[k]):\n",
    "                    dm[k] = sorted([dm[k],i[m]])[0]\n",
    "            else:\n",
    "                dt[k] = int(i[k])\n",
    "                dm[k] = i[m]\n",
    "print(dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вареники: Дикси\n"
     ]
    }
   ],
   "source": [
    "from csv import *\n",
    "with open(\"prices.csv\", \"r\" , encoding=\"utf-8\") as f:\n",
    "    readers = list(reader(f,delimiter=\";\")) \n",
    "    col = readers[0][1:]\n",
    "    readers = readers[1:]\n",
    "    res  = [readers[0][1],col[0],readers[0][0]]\n",
    "    for m, *price in readers: # перебераем магазины\n",
    "        for i in range(len(price)):\n",
    "            if int(price[i]) < int(res[0]):\n",
    "                res = [price[i],col[i],m]\n",
    "            elif int(price[i]) == int(res[0]):\n",
    "                res = sorted([res,[price[i],col[i],m]],key=lambda x: x[1])[0]\n",
    "    print(f\"{res[1]}: {res[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Творог',\n",
       " 'Гречка',\n",
       " 'Рис',\n",
       " 'Бородинский хлеб',\n",
       " 'Яблоки',\n",
       " 'Пельмени',\n",
       " 'Овсяное печенье',\n",
       " 'Спагетти',\n",
       " 'Печеная фасоль',\n",
       " 'Мороженое',\n",
       " 'Фарш',\n",
       " 'Вареники',\n",
       " 'Картофель',\n",
       " 'Батончик']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'69'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readers[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
