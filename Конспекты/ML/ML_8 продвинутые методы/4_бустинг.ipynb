{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем перейти к практической части, предлагаем ознакомиться с параметрами AdaBoost:\n",
    "\n",
    "- estimator — параметр отвечает за природу базовых моделей, по умолчанию это DecisionTreeRegressor c максимальной глубиной (max_depth) 3.\n",
    "- n_estimators — максимальное количество базовых моделей, по умолчанию равно 50. В случае идеального обучения алгоритм завершается ранее, чем данное значение.\n",
    "- learning_rate — темп обучения, параметр, добавляющий дополнительный множитель весу базовой модели, по умолчанию он равен 1.\n",
    "- loss{'linear', 'square', 'exponential'} — функция ошибки для обновления весов (в теоретической части мы рассматривали экспоненциальную форму обновления весов — 'exponential')\n",
    "- random_state — параметр, фиксирующий случайные процессы в модели.\n",
    "\n",
    "Для сравнимости результатов со случайным лесом возьмём количество базовых моделей, равное 10. Как говорилось ранее, глубина деревьев должна быть меньше, чем у случайного леса. По умолчанию она равна 3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\\\n",
    "    data = load_diabetes(as_frame=True)\n",
    "# Создаем матрицу наблюдений\n",
    "X = data['frame'].drop('target', axis=1)\n",
    "# Создаем вектор правильных ответов\n",
    "y = data['target']\n",
    " \n",
    "X.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для AdaBoost 3101.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Создаем объект класса дерева решений\n",
    "dt = DecisionTreeRegressor(\n",
    "    max_depth=3, #максимальная глубина дерева\n",
    "    random_state=42 #датчик генератора случайных чисел\n",
    ")\n",
    "# Создаем объект класса AdaBoost\n",
    "ada = AdaBoostRegressor(\n",
    "    estimator=dt, #базовая модель\n",
    "    n_estimators=100, #количество моделей в ансамбле\n",
    "    random_state=42 #датчик генератора случайных чисел\n",
    ")\n",
    "# Обучаем модель\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Формируем предсказание для тестовой выборки\n",
    "ada_pred  = ada.predict(X_test)\n",
    "\n",
    "# Оцениваем качество по метрике MSE\n",
    "print(f'Качество предсказания по MSE для AdaBoost {round(mean_squared_error(y_test, ada_pred),2)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для AdaBoost 2991.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для AdaBoost 3101.68\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(\n",
    "    max_depth=3, \n",
    "    random_state=42\n",
    ")\n",
    " \n",
    "ada = AdaBoostRegressor(\n",
    "\tbase_estimator=dt,\n",
    "random_state=42, \n",
    "n_estimators=50\n",
    ")\n",
    "ada.fit(X_train, y_train)\n",
    " \n",
    " \n",
    "ada_pred  = ada.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для AdaBoost {round(mean_squared_error(y_test, ada_pred),2)}')\n",
    " \n",
    "dt = DecisionTreeRegressor(\n",
    "    max_depth=3, \n",
    "    random_state=42\n",
    ")\n",
    " \n",
    "ada = AdaBoostRegressor(\n",
    "base_estimator=dt,\n",
    "random_state=42, \n",
    "n_estimators=100\n",
    ")\n",
    "ada.fit(X_train, y_train)\n",
    " \n",
    " \n",
    "ada_pred  = ada.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для AdaBoost {round(mean_squared_error(y_test, ada_pred),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг (регрессия)\n",
    "\n",
    "Основные параметры GradientBoostingRegressor:\n",
    "\n",
    "- loss — функция потерь. По умолчанию в регрессии 'squared_loss' - наша любимая MSE, а в классификации 'deviance' - логистическая функция потерь (logloss).\n",
    "- learning_rate — темп обучения. По умолчанию 0.1. \n",
    "- n_estimators — количество деревьев в бустинге (число  из бустинга). По умолчанию равно 100.\n",
    "- max_depth — максимальная глубина одного дерева. По умолчанию равна 3 — строятся короткие деревья с большим смещением.\n",
    "- min_samples_leaf — минимальное число объектов в листе. По умолчанию 1.\n",
    "- random_state — число, отвечающее за генерацию случайных чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для GradientBoostingRegressor 3477.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Создаем объект класса градиентный бустинг\n",
    "gb = GradientBoostingRegressor(\n",
    "    max_depth=3, #максимальная глубина дерева\n",
    "    n_estimators=10, #количество деревьев в ансамбле\n",
    "    random_state=42 #датчик генератора случайных чисел\n",
    ")\n",
    "\n",
    "# Обучаем модель\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Формируем предсказание для тестовой выборки\n",
    "gb_pred  = gb.predict(X_test)\n",
    "\n",
    "# Оцениваем качество по метрике MSE\n",
    "print(f'Качество предсказания по MSE для GradientBoostingRegressor {round(mean_squared_error(y_test, gb_pred),2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для GradientBoostingRegressor 3100.08\n",
      "Качество предсказания по MSE для GradientBoostingRegressor 3286.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Создаем объект класса градиентный бустинг\n",
    "gb = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=50 #количество деревьев в ансамбле\n",
    ")\n",
    "\n",
    "# Обучаем модель\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Формируем предсказание для тестовой выборки\n",
    "gb_pred  = gb.predict(X_test)\n",
    "\n",
    "# Оцениваем качество по метрике MSE\n",
    "print(f'Качество предсказания по MSE для GradientBoostingRegressor {round(mean_squared_error(y_test, gb_pred),2)}')\n",
    "\n",
    "gb = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=100 #количество деревьев в ансамбле\n",
    ")\n",
    "\n",
    "# Обучаем модель\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Формируем предсказание для тестовой выборки\n",
    "gb_pred  = gb.predict(X_test)\n",
    "\n",
    "# Оцениваем качество по метрике MSE\n",
    "print(f'Качество предсказания по MSE для GradientBoostingRegressor {round(mean_squared_error(y_test, gb_pred),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг (классификация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv(\"data/winequality-red.zip\",sep = \";\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Размерность обучающей выборки (1071, 11)\n",
      " Размерность тестовой выборки (528, 11)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"quality\"],axis= 1)\n",
    "\n",
    "y = (df['quality']>5).astype(int)\n",
    "# Разделим выборку на тренировочную и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "# Посмотрим на размерности выборок\n",
    "print(f' Размерность обучающей выборки {X_train.shape}')\n",
    "print(f' Размерность тестовой выборки {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71       238\n",
      "           1       0.77      0.73      0.75       290\n",
      "\n",
      "    accuracy                           0.73       528\n",
      "   macro avg       0.73      0.73      0.73       528\n",
      "weighted avg       0.73      0.73      0.73       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создаем модель градиентного бустинга\n",
    "gb = GradientBoostingClassifier(\n",
    "    loss='log_loss', #функция потерь\n",
    "    learning_rate=0.01, #темп обучения\n",
    "    n_estimators=200, #число деревьев\n",
    "    max_depth=3, #максимальная глубина дерева\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42 #генератор случайных чисел\n",
    ")\n",
    "# Обучаем модель\n",
    "gb.fit(X_train, y_train)\n",
    "# Формируем предсказание для тестовой выборки\n",
    "y_pred = gb.predict(X_test)\n",
    "# Посмотрим на основные метрики классификации\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64916863 0.35083137]\n",
      " [0.80459408 0.19540592]\n",
      " [0.66418585 0.33581415]\n",
      " ...\n",
      " [0.10699995 0.89300005]\n",
      " [0.70918506 0.29081494]\n",
      " [0.7486765  0.2513235 ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = gb.predict_proba(X_test)\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       238\n",
      "           1       0.81      0.83      0.82       290\n",
      "\n",
      "    accuracy                           0.80       528\n",
      "   macro avg       0.79      0.79      0.79       528\n",
      "weighted avg       0.80      0.80      0.80       528\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       506\n",
      "           1       1.00      1.00      1.00       565\n",
      "\n",
      "    accuracy                           1.00      1071\n",
      "   macro avg       1.00      1.00      1.00      1071\n",
      "weighted avg       1.00      1.00      1.00      1071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb1 = GradientBoostingClassifier(\n",
    "    loss='log_loss', #функция потерь\n",
    "    learning_rate=0.2, #темп обучения\n",
    "    n_estimators=500, #число деревьев\n",
    "    max_depth=3, #максимальная глубина дерева\n",
    "    min_samples_leaf=10, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел\n",
    ")\n",
    " \n",
    "gb1.fit(X_train, y_train)\n",
    "y_pred = gb1.predict(X_test)\n",
    "y_pred_t = gb1.predict(X_train)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(classification_report(y_train, y_pred_t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
